{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-de32f506b5ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGLMTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXGLMModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import XGLMTokenizer, XGLMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to load weights from pytorch checkpoint file for '/Users/kainylund/.cache/huggingface/transformers/bc076a53e578085d7fa695f675f89189a2ab26dba369fe44bc307bb55d5e8fd6.aca9c225689c3455ffed75ef09e381dc84b074e5da6f271ad350587596a0d654' at '/Users/kainylund/.cache/huggingface/transformers/bc076a53e578085d7fa695f675f89189a2ab26dba369fe44bc307bb55d5e8fd6.aca9c225689c3455ffed75ef09e381dc84b074e5da6f271ad350587596a0d654'. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py:349\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=347'>348</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=348'>349</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(checkpoint_file, map_location\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=349'>350</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/torch/serialization.py:527\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/torch/serialization.py?line=525'>526</a>\u001b[0m \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m--> <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/torch/serialization.py?line=526'>527</a>\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_reader(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/torch/serialization.py?line=527'>528</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/torch/serialization.py:224\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/torch/serialization.py?line=222'>223</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name_or_buffer):\n\u001b[0;32m--> <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/torch/serialization.py?line=223'>224</a>\u001b[0m     \u001b[39msuper\u001b[39m(_open_zipfile_reader, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mPyTorchFileReader(name_or_buffer))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: version_ <= kMaxSupportedFileFormatVersion INTERNAL ASSERT FAILED at /Users/distiller/project/conda/conda-bld/pytorch_1580186068235/work/caffe2/serialize/inline_container.cc:132, please report a bug to PyTorch. Attempted to read a PyTorch file with version 3, but the maximum supported version for reading is 2. Your PyTorch installation may be too old. (init at /Users/distiller/project/conda/conda-bld/pytorch_1580186068235/work/caffe2/serialize/inline_container.cc:132)\nframe #0: c10::Error::Error(c10::SourceLocation, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) + 135 (0x1725d6267 in libc10.dylib)\nframe #1: caffe2::serialize::PyTorchStreamReader::init() + 2350 (0x165bfe50e in libtorch.dylib)\nframe #2: caffe2::serialize::PyTorchStreamReader::PyTorchStreamReader(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) + 143 (0x165bfdb5f in libtorch.dylib)\nframe #3: void pybind11::cpp_function::initialize<void pybind11::detail::initimpl::constructor<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >::execute<pybind11::class_<caffe2::serialize::PyTorchStreamReader>, 0>(pybind11::class_<caffe2::serialize::PyTorchStreamReader>&)::'lambda'(pybind11::detail::value_and_holder&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >), void, pybind11::detail::value_and_holder&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, pybind11::name, pybind11::is_method, pybind11::sibling, pybind11::detail::is_new_style_constructor>(pybind11::class_<caffe2::serialize::PyTorchStreamReader>&&,  (*)(0...), void pybind11::detail::initimpl::constructor<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >::execute<pybind11::class_<caffe2::serialize::PyTorchStreamReader>, 0>(pybind11::class_<caffe2::serialize::PyTorchStreamReader>&)::'lambda'(pybind11::detail::value_and_holder&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >) const&...)::'lambda'(pybind11::detail::function_call&)::operator()(pybind11::detail::function_call&) const + 147 (0x1628cfd43 in libtorch_python.dylib)\nframe #4: pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 3382 (0x1622c83c6 in libtorch_python.dylib)\n<omitting python frames>\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py:353\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=351'>352</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(checkpoint_file) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=352'>353</a>\u001b[0m     \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39;49mread()\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=353'>354</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=354'>355</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou seem to have cloned a repository without having git-lfs installed. Please install \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=355'>356</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mgit-lfs and run `git lfs install` followed by `git lfs pull` in the folder \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=356'>357</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myou cloned.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=357'>358</a>\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/arkenv/lib/python3.8/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/codecs.py?line=320'>321</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m--> <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/codecs.py?line=321'>322</a>\u001b[0m (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer_decode(data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors, final)\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/codecs.py?line=322'>323</a>\u001b[0m \u001b[39m# keep undecoded input until the next call\u001b[39;00m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 64: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/kainylund/Desktop/ARK/ARK-pipelines/live-news/XGMLtest.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kainylund/Desktop/ARK/ARK-pipelines/live-news/XGMLtest.ipynb#ch0000001?line=0'>1</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m XGLMTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mfacebook/xglm-564M\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kainylund/Desktop/ARK/ARK-pipelines/live-news/XGMLtest.ipynb#ch0000001?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m XGLMModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mfacebook/xglm-564M\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kainylund/Desktop/ARK/ARK-pipelines/live-news/XGMLtest.ipynb#ch0000001?line=3'>4</a>\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer(\u001b[39m\"\u001b[39m\u001b[39mHello, my dog is cute\u001b[39m\u001b[39m\"\u001b[39m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kainylund/Desktop/ARK/ARK-pipelines/live-news/XGMLtest.ipynb#ch0000001?line=4'>5</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py:1797\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=1793'>1794</a>\u001b[0m \u001b[39mif\u001b[39;00m from_pt:\n\u001b[1;32m   <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=1794'>1795</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_sharded:\n\u001b[1;32m   <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=1795'>1796</a>\u001b[0m         \u001b[39m# Time to load the checkpoint\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=1796'>1797</a>\u001b[0m         state_dict \u001b[39m=\u001b[39m load_state_dict(resolved_archive_file)\n\u001b[1;32m   <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=1797'>1798</a>\u001b[0m     \u001b[39m# set dtype to instantiate the model under:\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=1798'>1799</a>\u001b[0m     \u001b[39m# 1. If torch_dtype is not None, we use that dtype\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=1799'>1800</a>\u001b[0m     \u001b[39m# 2. If torch_dtype is \"auto\", we auto-detect dtype from the loaded state_dict, by checking its first\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=1800'>1801</a>\u001b[0m     \u001b[39m#    weights entry - we assume all weights are of the same dtype\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=1801'>1802</a>\u001b[0m     \u001b[39m# we also may have config.torch_dtype available, but we won't rely on it till v5\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=1802'>1803</a>\u001b[0m     dtype_orig \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py:365\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=359'>360</a>\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=360'>361</a>\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to locate the file \u001b[39m\u001b[39m{\u001b[39;00mcheckpoint_file\u001b[39m}\u001b[39;00m\u001b[39m which is necessary to load this pretrained \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=361'>362</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mmodel. Make sure you have saved the model properly.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=362'>363</a>\u001b[0m             ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=363'>364</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mUnicodeDecodeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m--> <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=364'>365</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=365'>366</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to load weights from pytorch checkpoint file for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcheckpoint_file\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=366'>367</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mat \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcheckpoint_file\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=367'>368</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/kainylund/opt/anaconda3/envs/arkenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=368'>369</a>\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to load weights from pytorch checkpoint file for '/Users/kainylund/.cache/huggingface/transformers/bc076a53e578085d7fa695f675f89189a2ab26dba369fe44bc307bb55d5e8fd6.aca9c225689c3455ffed75ef09e381dc84b074e5da6f271ad350587596a0d654' at '/Users/kainylund/.cache/huggingface/transformers/bc076a53e578085d7fa695f675f89189a2ab26dba369fe44bc307bb55d5e8fd6.aca9c225689c3455ffed75ef09e381dc84b074e5da6f271ad350587596a0d654'. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True."
     ]
    }
   ],
   "source": [
    "tokenizer = XGLMTokenizer.from_pretrained(\"facebook/xglm-564M\")\n",
    "model = XGLMModel.from_pretrained(\"facebook/xglm-564M\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "899c603100ad424b173678bf29736c5bd1ec9a65678a0fad157cd1f02f15f28c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
